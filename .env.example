# ==============================================================================
# OpenZero â€” Environment Configuration Template
# ==============================================================================
# Rename this file to .env and fill in your secrets.
# NEVER commit the actual .env file to version control. house

# --- System Access ---
# The public or VPN IP address of your server.
# Used for generating dashboard and board links in briefings.
BASE_URL=http://your_server_ip_here

# --- Database (PostgreSQL) ---
# Used by both the backend and the Planka board.
DB_USER=zero
DB_PASSWORD=CHANGE_ME_STRONG_PASSWORD  # Create your own secure password here
DB_NAME=zero_db
DB_HOST=postgres                        # Internal Docker network name (auto-mapped to localhost in dev)
DB_PORT=5432

# --- Telegram Bot ---
# Get your token by talking to @BotFather on Telegram (https://t.me/botfather).
TELEGRAM_BOT_TOKEN=your_bot_token_here
# Your numerical Telegram User ID (e.g., 12345678). 
# Talk to @userinfobot (https://t.me/userinfobot) to find yours. 
# Only this ID can control the bot (Zero-Trust protection).
TELEGRAM_ALLOWED_USER_ID=your_telegram_user_id

# --- Time & Localization ---
# Used for scheduling briefings and context awareness.
# Find your IANA timezone string here: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
# Examples: Europe/Berlin, America/New_York, Asia/Tokyo
# Set to 'auto' for the system to attempt to deduce your location from calendar events.
USER_TIMEZONE=America/New_York

# --- Local AI (Ollama) ---
# Base URL for the Ollama API. 
# Inside Docker: http://ollama:11434
# Running locally: http://localhost:11434
OLLAMA_BASE_URL=http://ollama:11434      # Internal Docker URL (auto-mapped to localhost in dev)
# Model selection:
# - llama3.1:8b (Default, smart but slow on CPU)
# - llama3.2:3b (Lighter, faster on CPU)
OLLAMA_MODEL=llama3.1:8b

# --- Local Voice Transcription (Whisper) ---
# The internal URL for the whisper-asr container.
WHISPER_BASE_URL=http://whisper:9000    # Internal Docker URL (auto-mapped to localhost in dev)

# --- Vector Memory (Qdrant) ---
# Qdrant stores your semantic memories and notes.
QDRANT_HOST=qdrant                       # Internal Docker name (auto-mapped to localhost in dev)
QDRANT_PORT=6333
# Create your own unique API key here for security.
QDRANT_API_KEY=CHANGE_ME_QDRANT_KEY

# --- Task Board (Planka) ---
# The internal URL where the backend can find Planka.
PLANKA_BASE_URL=http://planka:1337       # Internal Docker URL (auto-mapped to localhost in dev)
# Default credentials created on first launch. 
# You will use these to log into the Planka PWA.
PLANKA_ADMIN_EMAIL=admin@example.com
PLANKA_ADMIN_PASSWORD=CHANGE_ME_PLANKA_PASS

# --- Intelligence Layer Settings ---
# Default provider for standard chat interactions. 
# Options: ollama (local, free), groq (cloud, fast), openai (cloud, advanced)
LLM_PROVIDER=ollama

# --- Cloud LLM Keys (Optional) ---
# Get your Groq API key from: https://console.groq.com/keys
GROQ_API_KEY=
# Get your OpenAI API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# --- Deep Thinking (/think command) ---
# Which provider to use for high-power reasoning.
# NOTE: These models run in the cloud (Groq/OpenAI), not on your VPS. 
# They are extremely fast but require an API key.
# LEAVE BLANK to disable the /think command.
DEEP_THINK_PROVIDER=
# The specific model for deep reasoning. 
# Options for Groq: llama-3.3-70b-specdec, llama3-70b-8192
# Options for OpenAI: o1-mini, gpt-4o
DEEP_THINK_MODEL=
